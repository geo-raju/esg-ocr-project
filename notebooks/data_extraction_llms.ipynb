{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ecb3862",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geo/Documents/esg-ocr-project/esg_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import uuid\n",
    "from typing import List, Optional, Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "import google.generativeai as genai\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fc718a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# File paths\n",
    "INPUT_DIR = \"../data\"\n",
    "INPUT_FILE = \"LFC.pdf\"\n",
    "OUTPUT_DIR = \"../output\"\n",
    "CHROMA_DB_PATH = \"../vectorstores\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(INPUT_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(CHROMA_DB_PATH, exist_ok=True)\n",
    "\n",
    "# Configure API\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "# File paths\n",
    "input_filepath = os.path.join(INPUT_DIR, INPUT_FILE)\n",
    "output_filepath = os.path.join(OUTPUT_DIR, f\"{os.path.splitext(INPUT_FILE)[0].lower()}_extracted_data.json\")\n",
    "CHROMA_DB_PATH = os.path.join(CHROMA_DB_PATH, f\"{os.path.splitext(INPUT_FILE)[0].lower()}_report_vectorstore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed65ddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PYDANTIC MODELS FOR STRUCTURED OUTPUT\n",
    "# =============================================================================\n",
    "\n",
    "class AnswerWithSources(BaseModel):\n",
    "    \"\"\"An answer to a specific question or extracted piece of information, with sources and reasoning.\"\"\"\n",
    "    answer: str = Field(description=\"The extracted answer or information.\")\n",
    "    sources: str = Field(description=\"Full direct text chunk from the context used to extract this information.\")\n",
    "    reasoning: str = Field(description=\"Explanation of how the answer was derived from the provided sources.\")\n",
    "\n",
    "\n",
    "class ConductedActionDetails(BaseModel):\n",
    "    \"\"\"Details for a specific conducted environmental action category.\"\"\"\n",
    "    progress_achieved_for_period: AnswerWithSources = Field(\n",
    "        description=\"Progress achieved for the reporting period regarding this environmental topic.\"\n",
    "    )\n",
    "    actual_targets_set_for_period: AnswerWithSources = Field(\n",
    "        description=\"Actual targets set for the reporting period regarding this environmental topic.\"\n",
    "    )\n",
    "    reasons_for_achieved_progress: AnswerWithSources = Field(\n",
    "        description=\"Reason(s) for the achieved progress regarding this environmental topic.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class ConductedActionCategory(BaseModel):\n",
    "    \"\"\"A specific category of conducted environmental action (e.g., Total Emissions).\"\"\"\n",
    "    category_name: str = Field(\n",
    "        description=\"The name of the environmental category (e.g., 'Total emissions', 'Total energy consumption').\"\n",
    "    )\n",
    "    details: ConductedActionDetails = Field(\n",
    "        description=\"Detailed progress, targets, and reasons for this category.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class ConductedActionsSection(BaseModel):\n",
    "    \"\"\"The main section for conducted environmental actions conducted during the reporting period.\"\"\"\n",
    "    categories_data: List[ConductedActionCategory] = Field(\n",
    "        description=\"A list of specific environmental categories with their respective progress, targets, and reasons.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class PlannedActionDetails(BaseModel):\n",
    "    \"\"\"Details for a specific planned environmental action category.\"\"\"\n",
    "    planned_or_targeted_progress: AnswerWithSources = Field(\n",
    "        description=\"Planned or targeted progress for the upcoming period regarding this environmental topic.\"\n",
    "    )\n",
    "    planned_actions_to_achieve_target: AnswerWithSources = Field(\n",
    "        description=\"Planned action(s) to achieve the target(s) for the upcoming period regarding this environmental topic.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class PlannedActionCategory(BaseModel):\n",
    "    \"\"\"A specific category of planned environmental action (e.g., Total Emissions).\"\"\"\n",
    "    category_name: str = Field(\n",
    "        description=\"The name of the planned environmental category (e.g., 'Total emissions', 'Total energy consumption').\"\n",
    "    )\n",
    "    details: PlannedActionDetails = Field(\n",
    "        description=\"Detailed planned progress and actions for this category.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class PlannedActionsSection(BaseModel):\n",
    "    \"\"\"The main section for environmental actions planned for the next reporting period.\"\"\"\n",
    "    categories_data: List[PlannedActionCategory] = Field(\n",
    "        description=\"A list of specific environmental categories with their respective planned progress and actions.\"\n",
    "    )\n",
    "\n",
    "    \n",
    "class EnvironmentalCampaign(BaseModel):\n",
    "    \"\"\"Information extracted about a specific environmental campaign or activity.\"\"\"\n",
    "    name_of_campaign_activity: AnswerWithSources = Field(\n",
    "        description=\"Name of the environmental campaign or activity.\"\n",
    "    )\n",
    "    purpose_and_goal: AnswerWithSources = Field(\n",
    "        description=\"Purpose and aspired goal of the campaign/activity.\"\n",
    "    )\n",
    "    description_and_scope: AnswerWithSources = Field(\n",
    "        description=\"Description and scope of the campaign.\"\n",
    "    )\n",
    "    qualitative_quantitative_results: AnswerWithSources = Field(\n",
    "        description=\"Qualitative and quantitative results of the campaign.\"\n",
    "    )\n",
    "    environmental_issues_addressed: AnswerWithSources = Field(\n",
    "        description=\"Environmental issues addressed by the campaign.\"\n",
    "    )\n",
    "    name_of_collaboration_partners: AnswerWithSources = Field(\n",
    "        description=\"Names of collaboration partners (e.g., fan club, local community, charity, foundation, sponsorship partner).\"\n",
    "    )\n",
    "    number_of_potential_individuals_reached: AnswerWithSources = Field(\n",
    "        description=\"Number of potential individuals reached by the campaign.\"\n",
    "    )\n",
    "    sdgs_addressed: List[AnswerWithSources] = Field(\n",
    "        description=\"Which of the 17 Sustainable Development Goals (SDGs) have been addressed by the campaign.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class EnvironmentalCampaignsList(BaseModel):\n",
    "    \"\"\"List of environmental campaigns extracted from the report.\"\"\"\n",
    "    campaigns: List[EnvironmentalCampaign] = Field(\n",
    "        description=\"A list of environmental campaigns and activities identified in the report.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class ESGReportExtractedInfo(BaseModel):\n",
    "    \"\"\"Comprehensive extracted information from an ESG report.\"\"\"\n",
    "    environmental_campaigns: List[EnvironmentalCampaign] = Field(\n",
    "        description=\"A list of environmental campaigns and activities identified in the report.\"\n",
    "    )\n",
    "    environmental_actions_conducted: Optional[ConductedActionsSection] = Field(\n",
    "        default=None,\n",
    "        description=\"Detailed information about environmental actions conducted during the reporting period.\"\n",
    "    )\n",
    "    environmental_actions_planned: Optional[PlannedActionsSection] = Field(\n",
    "        default=None,\n",
    "        description=\"Detailed information about environmental actions planned for the next reporting period.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "676750f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EMBEDDING FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def get_gemini_embedding_function():\n",
    "    \"\"\"Returns a function that embeds text using Gemini's embedding model.\"\"\"\n",
    "    def embed_text(text: str, task_type: str = \"SEMANTIC_SIMILARITY\") -> Optional[np.ndarray]:\n",
    "        \"\"\"Embeds a single string using the Gemini embedding model.\"\"\"\n",
    "        try:\n",
    "            response = genai.embed_content(\n",
    "                model=\"models/embedding-001\",\n",
    "                content=text,\n",
    "                task_type=task_type\n",
    "            )\n",
    "            return np.array(response['embedding'])\n",
    "        except Exception as e:\n",
    "            print(f\"Error embedding text with Gemini: {e}\")\n",
    "            return None\n",
    "    return embed_text\n",
    "\n",
    "\n",
    "class CustomGeminiEmbeddings(Embeddings):\n",
    "    \"\"\"\n",
    "    A LangChain Embeddings class wrapper for the Gemini embedding function.\n",
    "    This allows the Gemini embedder to be used with LangChain's vector stores.\n",
    "    \"\"\"\n",
    "    def __init__(self, gemini_embed_func):\n",
    "        self.gemini_embed_func = gemini_embed_func\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"\n",
    "        Embeds a list of documents for storage in a vector store.\n",
    "        Uses \"RETRIEVAL_DOCUMENT\" task type for optimal retrieval performance.\n",
    "        \"\"\"\n",
    "        embeddings_list = []\n",
    "        for text in texts:\n",
    "            embedding = self.gemini_embed_func(text, task_type=\"RETRIEVAL_DOCUMENT\")\n",
    "            if embedding is not None:\n",
    "                embeddings_list.append(embedding.tolist())\n",
    "            else:\n",
    "                # Handle cases where embedding fails\n",
    "                print(f\"Warning: Embedding failed for a document. Using a zero vector.\")\n",
    "                embeddings_list.append([0.0] * 768)  # Assuming 768 is the embedding dimension\n",
    "        return embeddings_list\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        \"\"\"\n",
    "        Embeds a single query string for similarity search.\n",
    "        Uses \"RETRIEVAL_QUERY\" task type.\n",
    "        \"\"\"\n",
    "        embedding = self.gemini_embed_func(text, task_type=\"RETRIEVAL_QUERY\")\n",
    "        if embedding is not None:\n",
    "            return embedding.tolist()\n",
    "        else:\n",
    "            print(f\"Warning: Embedding failed for the query. Using a zero vector.\")\n",
    "            return [0.0] * 768  # Assuming 768 is the embedding dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95363455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VECTOR STORE FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def create_vectorstore(chunks: List[Document], embedding_function_instance: Embeddings, vectorstore_path: str):\n",
    "    \"\"\"\n",
    "    Creates or loads a Chroma vector store from a list of document chunks.\n",
    "    Ensures uniqueness of documents based on content hash.\n",
    "    \"\"\"\n",
    "    print(f\"Attempting to create/load vector store at: {vectorstore_path}\")\n",
    "\n",
    "    # Generate unique IDs for each document based on its content\n",
    "    ids = [str(uuid.uuid5(uuid.NAMESPACE_DNS, doc.page_content)) for doc in chunks]\n",
    "\n",
    "    # Filter out duplicate chunks based on their generated IDs\n",
    "    unique_ids = set()\n",
    "    unique_chunks = []\n",
    "    for chunk, doc_id in zip(chunks, ids):\n",
    "        if doc_id not in unique_ids:\n",
    "            unique_ids.add(doc_id)\n",
    "            unique_chunks.append(chunk)\n",
    "\n",
    "    print(f\"Found {len(unique_chunks)} unique chunks out of {len(chunks)} total.\")\n",
    "\n",
    "    # Create or load the Chroma database\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=unique_chunks,\n",
    "        ids=list(unique_ids),\n",
    "        embedding=embedding_function_instance,\n",
    "        persist_directory=vectorstore_path\n",
    "    )\n",
    "    \n",
    "    print(f\"Vector store created/loaded and persisted successfully at: {vectorstore_path}\")\n",
    "    return vectorstore\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    \"\"\"Format documents for RAG context.\"\"\"\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea074fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DOCUMENT PROCESSING\n",
    "# =============================================================================\n",
    "\n",
    "def load_and_split_documents(file_path: str) -> List[Document]:\n",
    "    \"\"\"Load PDF and split into chunks.\"\"\"\n",
    "    print(f\"Loading document: {file_path}\")\n",
    "    \n",
    "    loader = PyPDFLoader(file_path)\n",
    "    pages = loader.load()\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1500,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \"]\n",
    "    )\n",
    "    \n",
    "    chunks = text_splitter.split_documents(pages)\n",
    "    print(f\"Document split into {len(chunks)} chunks\")\n",
    "    \n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e1634c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# RAG SETUP AND QUERIES\n",
    "# =============================================================================\n",
    "\n",
    "def setup_rag_chains(vectorstore, llm):\n",
    "    \"\"\"Set up RAG chains for different extraction tasks.\"\"\"\n",
    "    \n",
    "    # Create retriever with optimized parameters\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=\"similarity\", \n",
    "        search_kwargs={\"k\": 5}  # Increased from 3 to 5 for better context coverage\n",
    "    )\n",
    "    \n",
    "    # Define optimized RAG prompt template\n",
    "    rag_prompt_template = \"\"\"You are an expert ESG (Environmental, Social, Governance) data extraction specialist with deep knowledge of sustainability reporting standards, environmental metrics, and corporate responsibility frameworks.\n",
    "\n",
    "## TASK OVERVIEW:\n",
    "Your primary objective is to extract precise, structured information from ESG reports and sustainability documents. You must analyze the provided context thoroughly and extract relevant data according to the specified Pydantic model structure.\n",
    "\n",
    "## EXTRACTION PRINCIPLES:\n",
    "1. **ACCURACY FIRST**: Base all responses strictly on the provided context. Never invent, assume, or extrapolate information not present in the source material.\n",
    "\n",
    "2. **COMPREHENSIVE ANALYSIS**: \n",
    "   - Examine ALL provided context chunks thoroughly\n",
    "   - Look for information across different sections, pages, and document parts\n",
    "   - Consider synonyms, alternative terminology, and related concepts\n",
    "   - Connect information that may be scattered across multiple paragraphs\n",
    "\n",
    "3. **DIRECT EVIDENCE REQUIREMENT**:\n",
    "   - For each extracted piece of information, provide the EXACT source text that supports your answer\n",
    "   - Use direct quotes whenever possible, preserving original wording and formatting\n",
    "   - When paraphrasing is necessary, stay as close to the original language as possible\n",
    "\n",
    "4. **STRUCTURED OUTPUT COMPLIANCE**:\n",
    "   - Follow the Pydantic model structure exactly as specified\n",
    "   - Ensure all required fields are populated appropriately\n",
    "   - Use \"Information not available in the provided context\" for missing data rather than leaving fields empty\n",
    "\n",
    "5. **NUMERICAL DATA PRECISION**:\n",
    "   - Extract exact figures, percentages, dates, and metrics when available\n",
    "   - Preserve units of measurement, currency symbols, and time periods\n",
    "   - Note any baseline years, comparison periods, or contextual qualifiers\n",
    "\n",
    "6. **REASONING TRANSPARENCY**:\n",
    "   - Clearly explain how each answer was derived from the source material\n",
    "   - Show logical connections between questions and relevant context sections\n",
    "   - Highlight any assumptions or interpretations made during extraction\n",
    "\n",
    "## CONTEXT ANALYSIS GUIDELINES:\n",
    "- **Multiple Perspectives**: Consider how information might be presented in different formats (tables, charts, narrative text, bullet points)\n",
    "- **Cross-References**: Look for information that spans multiple sections or references other parts of the document\n",
    "- **Implicit Information**: Extract information that might be implied or stated indirectly\n",
    "- **Temporal Context**: Pay attention to reporting periods, historical comparisons, and future projections\n",
    "\n",
    "## QUALITY ASSURANCE:\n",
    "- **Consistency Check**: Ensure extracted information aligns logically across all fields\n",
    "- **Completeness Review**: Verify that all available relevant information has been captured\n",
    "- **Accuracy Validation**: Double-check that source quotes exactly match the original text\n",
    "\n",
    "## HANDLING MISSING INFORMATION:\n",
    "If specific information is not available in the context:\n",
    "- State explicitly: \"This information is not available in the provided context\"\n",
    "- Do not guess, estimate, or use general knowledge to fill gaps\n",
    "- Provide reasoning for why the information might be missing or where it might typically be found\n",
    "\n",
    "---\n",
    "\n",
    "## DOCUMENT CONTEXT:\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "## EXTRACTION REQUEST:\n",
    "{question}\n",
    "\n",
    "---\n",
    "\n",
    "## RESPONSE INSTRUCTIONS:\n",
    "Analyze the above context thoroughly and extract the requested information following the Pydantic model structure. Ensure every piece of extracted data is supported by direct evidence from the provided context.\"\"\"\n",
    "    \n",
    "    rag_prompt = ChatPromptTemplate.from_template(rag_prompt_template)\n",
    "    \n",
    "    # Create chains for different extraction tasks\n",
    "    conducted_actions_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | rag_prompt\n",
    "        | llm.with_structured_output(ConductedActionsSection, strict=True)\n",
    "    )\n",
    "    \n",
    "    planned_actions_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | rag_prompt\n",
    "        | llm.with_structured_output(PlannedActionsSection, strict=True)\n",
    "    )\n",
    "    \n",
    "    environmental_campaigns_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | rag_prompt\n",
    "        | llm.with_structured_output(EnvironmentalCampaignsList, strict=True)\n",
    "    )\n",
    "    \n",
    "    return conducted_actions_chain, planned_actions_chain, environmental_campaigns_chain\n",
    "\n",
    "def get_extraction_questions():\n",
    "    \"\"\"Define optimized questions for different extraction tasks.\"\"\"\n",
    "    \n",
    "    conducted_actions_question = \"\"\"\n",
    "    Analyze the ESG report and extract detailed information about CONDUCTED environmental actions during the current reporting period.\n",
    "    \n",
    "    For each of these environmental categories, identify:\n",
    "    - Total emissions (including Scope 1, 2, and 3 emissions, carbon footprint, GHG emissions)\n",
    "    - Total business travel (including team travel, staff travel, transportation)\n",
    "    - Total energy consumption (including electricity, gas, fuel, renewable energy usage)\n",
    "    - Total water consumption (including water usage, conservation efforts)\n",
    "    - Total paper consumption (including digital transformation efforts, paperless initiatives)\n",
    "    - Total waste generation (including waste reduction, recycling, circular economy efforts)\n",
    "    \n",
    "    For EACH category found, extract:\n",
    "    1. PROGRESS ACHIEVED: What specific measurable progress was made? Include quantitative metrics (percentages, absolute numbers, comparisons to baselines or previous years).\n",
    "    2. ACTUAL TARGETS: What were the specific targets or goals set for this reporting period? Include numerical targets and timeframes.\n",
    "    3. REASONS FOR PROGRESS: What specific actions, initiatives, or factors led to the achieved progress? Include implementation details and methodologies.\n",
    "    \n",
    "    Important guidelines:\n",
    "    - Look for synonyms and related terms (e.g., \"carbon footprint\" for emissions, \"energy efficiency\" for energy consumption)\n",
    "    - Extract exact figures, percentages, and metrics when available\n",
    "    - Include both absolute and relative improvements\n",
    "    - Note any certifications, standards, or methodologies mentioned\n",
    "    - If no information is found for a category, clearly state \"No conducted actions reported for this category\"\n",
    "    \"\"\"\n",
    "    \n",
    "    planned_actions_question = \"\"\"\n",
    "    Analyze the ESG report and extract detailed information about PLANNED environmental actions for future reporting periods.\n",
    "    \n",
    "    For each of these environmental categories, identify future plans and commitments:\n",
    "    - Total emissions (including net-zero commitments, carbon reduction targets, offset plans)\n",
    "    - Total business travel (including travel reduction policies, sustainable transport initiatives)\n",
    "    - Total energy consumption (including renewable energy transitions, efficiency improvements)\n",
    "    - Total water consumption (including conservation targets, efficiency measures)\n",
    "    - Total paper consumption (including digitization plans, sustainable sourcing)\n",
    "    - Total waste generation (including zero-waste goals, circular economy initiatives)\n",
    "    \n",
    "    For EACH category found, extract:\n",
    "    1. PLANNED/TARGETED PROGRESS: What specific measurable targets are set for future periods? Include numerical goals, percentages, and clear timeframes (e.g., by 2025, 2030, 2040).\n",
    "    2. PLANNED ACTIONS: What specific initiatives, strategies, or actions will be implemented to achieve these targets? Include implementation timelines, responsible parties, and methodologies.\n",
    "    \n",
    "    Important guidelines:\n",
    "    - Focus on future-oriented language (will, plan to, target, aim, commit to, by [year])\n",
    "    - Extract specific numerical targets and deadlines\n",
    "    - Look for strategic roadmaps, action plans, and investment commitments\n",
    "    - Include any mentions of standards, certifications, or frameworks to be adopted\n",
    "    - Note partnerships or collaborations planned for achieving targets\n",
    "    - If no future plans are mentioned for a category, clearly state \"No planned actions reported for this category\"\n",
    "    \"\"\"\n",
    "    \n",
    "    environmental_campaigns_question = \"\"\"\n",
    "    Comprehensively analyze the ESG report to identify and extract detailed information about ALL environmental campaigns, initiatives, activities, and programs mentioned.\n",
    "    \n",
    "    Look for various types of environmental activities including:\n",
    "    - Awareness campaigns and educational programs\n",
    "    - Community engagement initiatives\n",
    "    - Sustainability programs and projects\n",
    "    - Environmental partnerships and collaborations\n",
    "    - Green initiatives and eco-friendly activities\n",
    "    - Climate action programs\n",
    "    - Conservation efforts and biodiversity projects\n",
    "    - Stakeholder engagement on environmental issues\n",
    "    - Environmental advocacy and policy initiatives\n",
    "    - Green technology implementations\n",
    "    \n",
    "    For EACH campaign/activity identified, extract comprehensive details:\n",
    "    \n",
    "    1. NAME: The specific name or title of the campaign/activity. If no formal name exists, create a descriptive title based on the content.\n",
    "    \n",
    "    2. PURPOSE & GOAL: The intended objectives, mission, and aspirational outcomes. What environmental impact is the campaign trying to achieve?\n",
    "    \n",
    "    3. DESCRIPTION & SCOPE: Detailed description of what the campaign involves, its scope, duration, geographic reach, and key components or phases.\n",
    "    \n",
    "    4. RESULTS: Both qualitative and quantitative outcomes, impacts, and achievements. Include metrics, participation numbers, environmental benefits, and success indicators.\n",
    "    \n",
    "    5. ENVIRONMENTAL ISSUES: Specific environmental challenges, problems, or areas addressed (e.g., climate change, biodiversity loss, pollution, resource depletion).\n",
    "    \n",
    "    6. COLLABORATION PARTNERS: Names of all partners involved, including:\n",
    "       - Fan clubs and supporter groups\n",
    "       - Local communities and neighborhoods\n",
    "       - Charities and non-profit organizations\n",
    "       - Foundations and environmental groups\n",
    "       - Sponsorship and business partners\n",
    "       - Government agencies and institutions\n",
    "       - Academic institutions and schools\n",
    "    \n",
    "    7. REACH: Number of people, communities, or stakeholders potentially reached or engaged by the campaign.\n",
    "    \n",
    "    8. SDGs ADDRESSED: Which of the 17 UN Sustainable Development Goals are specifically addressed, with explanations of how the campaign contributes to each goal.\n",
    "    \n",
    "    Important guidelines:\n",
    "    - Don't miss smaller initiatives or brief mentions of environmental activities\n",
    "    - Look for both formal programs and informal/ad-hoc environmental efforts\n",
    "    - Extract information even if incomplete - capture what's available\n",
    "    - Consider the full lifecycle of campaigns from planning to evaluation\n",
    "    - Include both internal (employee-focused) and external (community-focused) campaigns\n",
    "    - Look for environmental messaging, communications, and awareness efforts\n",
    "    \"\"\"\n",
    "    \n",
    "    return conducted_actions_question, planned_actions_question, environmental_campaigns_question\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d104b472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ESG DATA EXTRACTION PIPELINE\n",
      "================================================================================\n",
      "\n",
      "1. Loading and processing documents...\n",
      "Loading document: data/LFC.pdf\n",
      "Document split into 62 chunks\n",
      "\n",
      "2. Initializing embedding function...\n",
      "\n",
      "3. Creating/loading vector store...\n",
      "Attempting to create/load vector store at: ./lfc_report_vectorstore\n",
      "Found 62 unique chunks out of 62 total.\n",
      "Vector store created/loaded and persisted successfully at: ./lfc_report_vectorstore\n",
      "\n",
      "4. Setting up RAG chains...\n",
      "\n",
      "5. Extracting information...\n",
      "   - Extracting conducted actions...\n",
      "   - Extracting planned actions...\n",
      "   - Extracting environmental campaigns...\n",
      "\n",
      "6. Combining results...\n",
      "\n",
      "7. Saving results...\n",
      "✓ Data successfully saved to: output/lfc_extracted_data.json\n",
      "✓ Extracted 12 environmental campaigns\n",
      "✓ Extracted 6 conducted action categories\n",
      "✓ Extracted 6 planned action categories\n",
      "\n",
      "================================================================================\n",
      "EXTRACTION COMPLETED SUCCESSFULLY!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# MAIN EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ESG DATA EXTRACTION PIPELINE\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 1. Load and process documents\n",
    "    print(\"\\n1. Loading and processing documents...\")\n",
    "    chunks = load_and_split_documents(input_filepath)\n",
    "    \n",
    "    # 2. Initialize embedding function\n",
    "    print(\"\\n2. Initializing embedding function...\")\n",
    "    raw_gemini_embedder = get_gemini_embedding_function()\n",
    "    custom_langchain_embeddings = CustomGeminiEmbeddings(raw_gemini_embedder)\n",
    "    \n",
    "    # 3. Create/load vector store\n",
    "    print(\"\\n3. Creating/loading vector store...\")\n",
    "    vectorstore = create_vectorstore(\n",
    "        chunks=chunks,\n",
    "        embedding_function_instance=custom_langchain_embeddings,\n",
    "        vectorstore_path=CHROMA_DB_PATH\n",
    "    )\n",
    "    \n",
    "    # 4. Initialize LLM and setup RAG chains\n",
    "    print(\"\\n4. Setting up RAG chains...\")\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.2, google_api_key=GEMINI_API_KEY)\n",
    "    \n",
    "    conducted_actions_chain, planned_actions_chain, environmental_campaigns_chain = setup_rag_chains(vectorstore, llm)\n",
    "    \n",
    "    # 5. Get extraction questions\n",
    "    conducted_actions_question, planned_actions_question, environmental_campaigns_question = get_extraction_questions()\n",
    "    \n",
    "    # 6. Extract information\n",
    "    print(\"\\n5. Extracting information...\")\n",
    "    print(\"   - Extracting conducted actions...\")\n",
    "    extracted_conducted_actions = conducted_actions_chain.invoke(conducted_actions_question)\n",
    "    \n",
    "    print(\"   - Extracting planned actions...\")\n",
    "    extracted_planned_actions = planned_actions_chain.invoke(planned_actions_question)\n",
    "    \n",
    "    print(\"   - Extracting environmental campaigns...\")\n",
    "    extracted_campaigns = environmental_campaigns_chain.invoke(environmental_campaigns_question)\n",
    "    \n",
    "    # 7. Combine results\n",
    "    print(\"\\n6. Combining results...\")\n",
    "    extracted_esg_data = ESGReportExtractedInfo(\n",
    "        environmental_actions_conducted=extracted_conducted_actions,\n",
    "        environmental_actions_planned=extracted_planned_actions,\n",
    "        environmental_campaigns=extracted_campaigns.campaigns\n",
    "    )\n",
    "    \n",
    "    # 8. Save results\n",
    "    print(\"\\n7. Saving results...\")\n",
    "    try:\n",
    "        json_output = extracted_esg_data.model_dump_json(indent=2)\n",
    "        \n",
    "        with open(output_filepath, 'w', encoding='utf-8') as f:\n",
    "            f.write(json_output)\n",
    "        \n",
    "        print(f\"✓ Data successfully saved to: {output_filepath}\")\n",
    "        print(f\"✓ Extracted {len(extracted_esg_data.environmental_campaigns)} environmental campaigns\")\n",
    "        print(f\"✓ Extracted {len(extracted_esg_data.environmental_actions_conducted.categories_data) if extracted_esg_data.environmental_actions_conducted else 0} conducted action categories\")\n",
    "        print(f\"✓ Extracted {len(extracted_esg_data.environmental_actions_planned.categories_data) if extracted_esg_data.environmental_actions_planned else 0} planned action categories\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error saving results: {e}\")\n",
    "        return False\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"EXTRACTION COMPLETED SUCCESSFULLY!\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        success = main()\n",
    "        if not success:\n",
    "            exit(1)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during execution: {e}\")\n",
    "        exit(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esg_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
